"use strict";(globalThis.webpackChunkhertzbeat=globalThis.webpackChunkhertzbeat||[]).push([[19787],{3963(e,n,t){t.r(n),t.d(n,{assets:()=>c,contentTitle:()=>r,default:()=>m,frontMatter:()=>o,metadata:()=>l,toc:()=>p});var i=t(44320),a=(t(37953),t(58860));const o={title:"\u5982\u4f55\u53c2\u4e0e\u5f00\u53d1\u81ea\u5b9a\u4e49Collector",author:"zhangshenghang",author_title:"zhangshenghang",author_url:"https://github.com/zhangshenghang",tags:["opensource","practice"],keywords:["open source monitoring system","alerting system"]},r=void 0,l={permalink:"/zh-cn/blog/2024/11/24/custom-development",editUrl:"https://github.com/apache/hertzbeat/edit/master/home/i18n/zh-cn/docusaurus-plugin-content-blog/2024-11-24-custom-development.md",source:"@site/i18n/zh-cn/docusaurus-plugin-content-blog/2024-11-24-custom-development.md",title:"\u5982\u4f55\u53c2\u4e0e\u5f00\u53d1\u81ea\u5b9a\u4e49Collector",description:"Collector\u6a21\u5757\u4ecb\u7ecd",date:"2024-11-24T00:00:00.000Z",formattedDate:"2024\u5e7411\u670824\u65e5",tags:[{label:"opensource",permalink:"/zh-cn/blog/tags/opensource"},{label:"practice",permalink:"/zh-cn/blog/tags/practice"}],readingTime:12.35,hasTruncateMarker:!1,authors:[{name:"zhangshenghang",title:"zhangshenghang",url:"https://github.com/zhangshenghang"}],frontMatter:{title:"\u5982\u4f55\u53c2\u4e0e\u5f00\u53d1\u81ea\u5b9a\u4e49Collector",author:"zhangshenghang",author_title:"zhangshenghang",author_url:"https://github.com/zhangshenghang",tags:["opensource","practice"],keywords:["open source monitoring system","alerting system"]},prevItem:{title:"GSOC\u8c37\u6b4c\u7f16\u7a0b\u4e4b\u590f2025\u62db\u52df\u4e2d\uff5c\u671f\u5f85\u60a8\u7684\u63d0\u6848",permalink:"/zh-cn/blog/2025/03/03/gsoc-2025"},nextItem:{title:"Apache HertzBeat\u2122 1.6.1 \u53d1\u5e03\u516c\u544a",permalink:"/zh-cn/blog/2024/11/09/hertzbeat-v1.6.1"}},c={authorsImageUrls:[void 0]},p=[{value:"Collector\u6a21\u5757\u4ecb\u7ecd",id:"collector\u6a21\u5757\u4ecb\u7ecd",level:2},{value:"\u65b0\u589eCollector\u76d1\u63a7",id:"\u65b0\u589ecollector\u76d1\u63a7",level:2},{value:"1. \u521b\u5efa<code>kafka-collector</code>\u6a21\u5757",id:"1-\u521b\u5efakafka-collector\u6a21\u5757",level:3},{value:"2. \u65b0\u589eKafka\u534f\u8bae\u7c7b",id:"2-\u65b0\u589ekafka\u534f\u8bae\u7c7b",level:3},{value:"3. \u5728Metrics\u4e2d\u6dfb\u52a0Kafka\u652f\u6301",id:"3-\u5728metrics\u4e2d\u6dfb\u52a0kafka\u652f\u6301",level:3},{value:"4. \u65b0\u589e\u5e38\u91cf",id:"4-\u65b0\u589e\u5e38\u91cf",level:3},{value:"5. \u65b0\u589eKafka\u8fde\u63a5\u7c7b",id:"5-\u65b0\u589ekafka\u8fde\u63a5\u7c7b",level:3},{value:"6. \u5b9e\u73b0Kafka\u91c7\u96c6\u7c7b",id:"6-\u5b9e\u73b0kafka\u91c7\u96c6\u7c7b",level:3},{value:"7. \u914d\u7f6eSPI\u670d\u52a1\u6587\u4ef6",id:"7-\u914d\u7f6espi\u670d\u52a1\u6587\u4ef6",level:3},{value:"8. \u5728Collector\u6a21\u5757\u6dfb\u52a0Kafka\u4f9d\u8d56",id:"8-\u5728collector\u6a21\u5757\u6dfb\u52a0kafka\u4f9d\u8d56",level:3},{value:"\u6dfb\u52a0\u914d\u7f6e\u89e3\u6790\u6587\u4ef6",id:"\u6dfb\u52a0\u914d\u7f6e\u89e3\u6790\u6587\u4ef6",level:2},{value:"\u5f00\u53d1\u8c03\u8bd5",id:"\u5f00\u53d1\u8c03\u8bd5",level:2}],s={toc:p};function m({components:e,...n}){return(0,a.yg)("wrapper",(0,i.A)({},s,n,{components:e,mdxType:"MDXLayout"}),(0,a.yg)("h2",{id:"collector\u6a21\u5757\u4ecb\u7ecd"},"Collector\u6a21\u5757\u4ecb\u7ecd"),(0,a.yg)("p",null,(0,a.yg)("img",{alt:"model-desc",src:t(53384).A,width:"683",height:"203"})),(0,a.yg)("p",null,"Collector\u6a21\u5757\u6574\u4f53\u7ed3\u6784\u53ef\u4ee5\u5206\u4e3a\u56db\u4e2a\u4e3b\u8981\u90e8\u5206\uff0c\u6bcf\u4e2a\u90e8\u5206\u627f\u62c5\u4e0d\u540c\u7684\u804c\u8d23\uff1a"),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("p",{parentName:"li"},(0,a.yg)("strong",{parentName:"p"},"Collector\u5165\u53e3"),"\uff1a\u8fd9\u662fCollector\u6a21\u5757\u7684\u8fd0\u884c\u5165\u53e3\uff0c\u542f\u52a8\u540e\u4f1a\u901a\u8fc7\u8fd9\u4e2a\u5165\u53e3\u6765\u6267\u884c\u91c7\u96c6\u4efb\u52a1\u3002")),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("p",{parentName:"li"},(0,a.yg)("strong",{parentName:"p"},"collector-basic"),"\uff1a\u8be5\u6a21\u5757\u4e3b\u8981\u5305\u542b\u4e86\u57fa\u7840\u7684Collector\u5b9e\u73b0\uff0c\u5982HTTP\u3001JDBC\u7b49\u901a\u7528\u534f\u8bae\u7684\u76d1\u63a7\u3002\u8fd9\u91cc\u7684Collector\u901a\u5e38\u4e0d\u9700\u8981\u989d\u5916\u7684\u4e13\u6709\u4f9d\u8d56\uff0c\u80fd\u6ee1\u8db3\u5927\u591a\u6570\u57fa\u7840\u76d1\u63a7\u9700\u6c42\u3002")),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("p",{parentName:"li"},(0,a.yg)("strong",{parentName:"p"},"collector-common"),"\uff1a\u8fd9\u4e2a\u6a21\u5757\u5b58\u653e\u4e86\u4e00\u4e9b\u901a\u7528\u7684\u5de5\u5177\u7c7b\u548c\u65b9\u6cd5\uff0c\u6bd4\u5982\u516c\u5171\u7684\u8fde\u63a5\u6c60\u3001\u7f13\u5b58\u673a\u5236\u7b49\uff0c\u5176\u4ed6\u6a21\u5757\u53ef\u4ee5\u590d\u7528\u8fd9\u91cc\u7684\u4ee3\u7801\u3002")),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("p",{parentName:"li"},(0,a.yg)("strong",{parentName:"p"},"collector-xxx"),"\uff1a\u8fd9\u662f\u4e3a\u4e0d\u540c\u670d\u52a1\u6216\u534f\u8bae\u7684\u6269\u5c55Collector\u6a21\u5757\u3002\u4f8b\u5982\uff0cMongoDB\u3001RocketMQ\u7b49\u7279\u5b9a\u670d\u52a1\u7684\u76d1\u63a7\uff0c\u5f80\u5f80\u9700\u8981\u5f15\u5165\u5b83\u4eec\u7684\u4e13\u6709\u4f9d\u8d56\uff0c\u5e76\u5728\u5404\u81ea\u6a21\u5757\u4e2d\u8fdb\u884c\u5f00\u53d1\u3002\u4ee5\u4e0b\u662fMongoDB\u7684\u4f9d\u8d56\u793a\u4f8b\uff1a"),(0,a.yg)("pre",{parentName:"li"},(0,a.yg)("code",{parentName:"pre",className:"language-xml"},"<dependency>\n    <groupId>org.mongodb</groupId>\n    <artifactId>mongodb-driver-sync</artifactId>\n</dependency>\n")))),(0,a.yg)("p",null,"\u901a\u8fc7\u8fd9\u79cd\u6a21\u5757\u5316\u8bbe\u8ba1\uff0cCollector\u53ef\u4ee5\u8f7b\u677e\u5730\u6269\u5c55\u5e76\u9002\u914d\u591a\u79cd\u76d1\u63a7\u573a\u666f\u3002"),(0,a.yg)("h2",{id:"\u65b0\u589ecollector\u76d1\u63a7"},"\u65b0\u589eCollector\u76d1\u63a7"),(0,a.yg)("p",null,"\u63a5\u4e0b\u6765\uff0c\u6211\u4eec\u5c06\u901a\u8fc7\u521b\u5efa\u4e00\u4e2a",(0,a.yg)("inlineCode",{parentName:"p"},"kafka-collector"),"\u6a21\u5757\u7684\u5b9e\u9645\u6848\u4f8b\u6765\u5c55\u793a\u5982\u4f55\u5f00\u53d1\u65b0\u7684Collector\u3002"),(0,a.yg)("h3",{id:"1-\u521b\u5efakafka-collector\u6a21\u5757"},"1. \u521b\u5efa",(0,a.yg)("inlineCode",{parentName:"h3"},"kafka-collector"),"\u6a21\u5757"),(0,a.yg)("p",null,"\u9996\u5148\uff0c\u6211\u4eec\u9700\u8981\u5728\u9879\u76ee\u4e2d\u521b\u5efa\u4e00\u4e2a\u65b0\u7684\u6a21\u5757\u7528\u4e8eKafka\u7684\u76d1\u63a7\uff0c\u547d\u540d\u4e3a",(0,a.yg)("inlineCode",{parentName:"p"},"kafka-collector"),"\u3002\u5e76\u5728\u8be5\u6a21\u5757\u4e2d\u4fee\u6539",(0,a.yg)("inlineCode",{parentName:"p"},"pom.xml"),"\u6587\u4ef6\u3002\n",(0,a.yg)("img",{alt:"model-create",src:t(98039).A,width:"1295",height:"835"})),(0,a.yg)("p",null,(0,a.yg)("strong",{parentName:"p"},(0,a.yg)("inlineCode",{parentName:"strong"},"pom.xml"),"\u914d\u7f6e")),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-xml"},'<?xml version="1.0" encoding="UTF-8"?>\n<project xmlns="http://maven.apache.org/POM/4.0.0"\n         xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"\n         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">\n    <modelVersion>4.0.0</modelVersion>\n    <parent>\n        <groupId>org.apache.hertzbeat</groupId>\n        <artifactId>hertzbeat-collector</artifactId>\n        <version>2.0-SNAPSHOT</version>\n    </parent>\n\n    <artifactId>hertzbeat-collector-kafka</artifactId>\n    <name>${project.artifactId}</name>\n\n    <properties>\n        <maven.compiler.source>17</maven.compiler.source>\n        <maven.compiler.target>17</maven.compiler.target>\n        <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>\n    </properties>\n\n    <dependencies>\n        <dependency>\n            <groupId>org.apache.hertzbeat</groupId>\n            <artifactId>hertzbeat-collector-common</artifactId>\n            <scope>provided</scope>\n        </dependency>\n        \x3c!-- kafka --\x3e\n        <dependency>\n            <groupId>org.apache.kafka</groupId>\n            <artifactId>kafka-clients</artifactId>\n        </dependency>\n    </dependencies>\n</project>\n')),(0,a.yg)("p",null,"\u6b64\u5904\u9700\u8981\u6ce8\u610f\u7684\u5185\u5bb9\uff1a"),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("inlineCode",{parentName:"li"},"artifactId"),"\u8bbe\u4e3a",(0,a.yg)("inlineCode",{parentName:"li"},"hertzbeat-collector-kafka"),"\uff0c\u4ee5\u4fdd\u6301\u547d\u540d\u4e00\u81f4\u6027\u3002"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("inlineCode",{parentName:"li"},"dependencies"),"\u4e2d\u624b\u52a8\u6dfb\u52a0Kafka\u6240\u9700\u7684\u4f9d\u8d56\u3002")),(0,a.yg)("h3",{id:"2-\u65b0\u589ekafka\u534f\u8bae\u7c7b"},"2. \u65b0\u589eKafka\u534f\u8bae\u7c7b"),(0,a.yg)("p",null,"\u4e3a\u4e86\u8ba9Collector\u6a21\u5757\u80fd\u591f\u5904\u7406Kafka\u7684\u76d1\u63a7\u534f\u8bae\uff0c\u6211\u4eec\u9700\u8981\u521b\u5efa\u4e00\u4e2a",(0,a.yg)("inlineCode",{parentName:"p"},"KafkaProtocol"),"\u7c7b\u6765\u5b9a\u4e49Kafka\u7684\u8fde\u63a5\u53c2\u6570\u3002\u8be5\u7c7b\u4f4d\u4e8e",(0,a.yg)("inlineCode",{parentName:"p"},"common/src/main/java/org/apache/hertzbeat/common/entity/job/protocol/KafkaProtocol.java"),"\u3002"),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-java"},"package org.apache.hertzbeat.common.entity.job.protocol;\n\nimport lombok.AllArgsConstructor;\nimport lombok.Builder;\nimport lombok.Data;\nimport lombok.NoArgsConstructor;\n\n@Data\n@Builder\n@AllArgsConstructor\n@NoArgsConstructor\npublic class KafkaProtocol {\n\n    /**\n     * IP\u5730\u5740\u6216\u57df\u540d\n     */\n    private String host;\n\n    /**\n     * \u7aef\u53e3\u53f7\n     */\n    private String port;\n\n    /**\n     * \u8d85\u65f6\u65f6\u95f4\n     */\n    private String timeout;\n\n    /**\n     * \u6307\u4ee4\n     */\n    private String command;\n}\n")),(0,a.yg)("h3",{id:"3-\u5728metrics\u4e2d\u6dfb\u52a0kafka\u652f\u6301"},"3. \u5728Metrics\u4e2d\u6dfb\u52a0Kafka\u652f\u6301"),(0,a.yg)("p",null,"\u5728",(0,a.yg)("inlineCode",{parentName:"p"},"common/src/main/java/org/apache/hertzbeat/common/entity/job/Metrics.java"),"\u7c7b\u4e2d\uff0c\u52a0\u5165Kafka\u534f\u8bae\u7684\u652f\u6301\u3002"),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-java"},"private KafkaProtocol kclient;\n")),(0,a.yg)("h3",{id:"4-\u65b0\u589e\u5e38\u91cf"},"4. \u65b0\u589e\u5e38\u91cf"),(0,a.yg)("p",null,"\u5728",(0,a.yg)("inlineCode",{parentName:"p"},"DispatchConstants"),"\u7c7b\u4e2d\u5b9a\u4e49Kafka\u534f\u8bae\u7684\u5e38\u91cf\u3002"),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-java"},'String PROTOCOL_KAFKA = "kclient";\n')),(0,a.yg)("h3",{id:"5-\u65b0\u589ekafka\u8fde\u63a5\u7c7b"},"5. \u65b0\u589eKafka\u8fde\u63a5\u7c7b"),(0,a.yg)("p",null,(0,a.yg)("inlineCode",{parentName:"p"},"KafkaConnect"),"\u7c7b\u7528\u4e8e\u7ba1\u7406Kafka Admin\u7684\u8fde\u63a5\u903b\u8f91\u3002"),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-java"},"package org.apache.hertzbeat.collector.collect.kafka;\n\nimport org.apache.hertzbeat.collector.collect.common.cache.AbstractConnection;\nimport org.apache.kafka.clients.admin.AdminClient;\nimport org.apache.kafka.clients.admin.AdminClientConfig;\nimport org.apache.kafka.clients.admin.KafkaAdminClient;\n\nimport java.util.Properties;\n\npublic class KafkaConnect extends AbstractConnection<AdminClient> {\n\n    private static AdminClient adminClient;\n\n    public KafkaConnect(String brokerList) {\n        Properties properties = new Properties();\n        properties.put(AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG, brokerList);\n        properties.put(AdminClientConfig.RETRIES_CONFIG, 3);\n        adminClient = KafkaAdminClient.create(properties);\n    }\n\n    @Override\n    public AdminClient getConnection() {\n        return adminClient;\n    }\n\n    @Override\n    public void closeConnection() throws Exception {\n        if (this.adminClient != null) {\n            this.adminClient.close();\n        }\n    }\n\n    public static synchronized AdminClient getAdminClient(String brokerList) {\n        if (adminClient == null) {\n            Properties properties = new Properties();\n            properties.put(AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG, brokerList);\n            adminClient = KafkaAdminClient.create(properties);\n        }\n        return adminClient;\n    }\n\n}\n")),(0,a.yg)("h3",{id:"6-\u5b9e\u73b0kafka\u91c7\u96c6\u7c7b"},"6. \u5b9e\u73b0Kafka\u91c7\u96c6\u7c7b"),(0,a.yg)("p",null,"\u7ee7\u627f",(0,a.yg)("inlineCode",{parentName:"p"},"AbstractCollect"),"\u7c7b\uff0c\u5e76\u5728\u5176\u4e2d\u5b9e\u73b0\u5177\u4f53\u7684\u6570\u636e\u91c7\u96c6\u903b\u8f91\u3002\u8fd9\u91cc\u4e0d\u5bf9\u5177\u4f53\u903b\u8f91\u8fdb\u884c\u4ecb\u7ecd\u4e86\u3002"),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-java"},'/*\n * Licensed to the Apache Software Foundation (ASF) under one or more\n * contributor license agreements.  See the NOTICE file distributed with\n * this work for additional information regarding copyright ownership.\n * The ASF licenses this file to You under the Apache License, Version 2.0\n * (the "License"); you may not use this file except in compliance with\n * the License.  You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an "AS IS" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\npackage org.apache.hertzbeat.collector.collect.kafka;\n\nimport lombok.extern.slf4j.Slf4j;\nimport org.apache.hertzbeat.collector.collect.AbstractCollect;\nimport org.apache.hertzbeat.collector.dispatch.DispatchConstants;\nimport org.apache.hertzbeat.common.entity.job.Metrics;\nimport org.apache.hertzbeat.common.entity.job.protocol.KafkaProtocol;\nimport org.apache.hertzbeat.common.entity.message.CollectRep;\nimport org.apache.kafka.clients.admin.AdminClient;\nimport org.apache.kafka.clients.admin.DescribeTopicsResult;\nimport org.apache.kafka.clients.admin.ListTopicsOptions;\nimport org.apache.kafka.clients.admin.ListTopicsResult;\nimport org.apache.kafka.clients.admin.OffsetSpec;\nimport org.apache.kafka.clients.admin.TopicDescription;\nimport org.apache.kafka.common.TopicPartition;\nimport org.apache.kafka.common.TopicPartitionInfo;\nimport org.springframework.util.Assert;\n\nimport java.util.Collections;\nimport java.util.List;\nimport java.util.Map;\nimport java.util.Set;\nimport java.util.concurrent.ExecutionException;\nimport java.util.concurrent.TimeUnit;\nimport java.util.concurrent.TimeoutException;\n\n@Slf4j\npublic class KafkaCollectImpl extends AbstractCollect {\n\n    @Override\n    public void preCheck(Metrics metrics) throws IllegalArgumentException {\n        KafkaProtocol kafkaProtocol = metrics.getKclient();\n        // Ensure that metrics and kafkaProtocol are not null\n        Assert.isTrue(metrics != null && kafkaProtocol != null, "Kafka collect must have kafkaProtocol params");\n        // Ensure that host and port are not empty\n        Assert.hasText(kafkaProtocol.getHost(), "Kafka Protocol host is required.");\n        Assert.hasText(kafkaProtocol.getPort(), "Kafka Protocol port is required.");\n    }\n\n    @Override\n    public void collect(CollectRep.MetricsData.Builder builder, long monitorId, String app, Metrics metrics) {\n        try {\n            KafkaProtocol kafkaProtocol = metrics.getKclient();\n            String command = kafkaProtocol.getCommand();\n            boolean isKafkaCommand = SupportedCommand.isKafkaCommand(command);\n            if (!isKafkaCommand) {\n                log.error("Unsupported command: {}", command);\n                return;\n            }\n\n            // Create AdminClient with the provided host and port\n            AdminClient adminClient = KafkaConnect.getAdminClient(kafkaProtocol.getHost() + ":" + kafkaProtocol.getPort());\n\n            // Execute the appropriate collection method based on the command\n            switch (SupportedCommand.fromCommand(command)) {\n                case TOPIC_DESCRIBE:\n                    collectTopicDescribe(builder, adminClient);\n                    break;\n                case TOPIC_LIST:\n                    collectTopicList(builder, adminClient);\n                    break;\n                case TOPIC_OFFSET:\n                    collectTopicOffset(builder, adminClient);\n                    break;\n                default:\n                    log.error("Unsupported command: {}", command);\n                    break;\n            }\n        } catch (InterruptedException | ExecutionException e) {\n            log.error("Kafka collect error", e);\n        }\n    }\n\n    /**\n     * Collect the earliest and latest offsets for each topic\n     *\n     * @param builder     The MetricsData builder\n     * @param adminClient The AdminClient\n     * @throws InterruptedException If the thread is interrupted\n     * @throws ExecutionException   If an error occurs during execution\n     */\n    private void collectTopicOffset(CollectRep.MetricsData.Builder builder, AdminClient adminClient) throws InterruptedException, ExecutionException {\n        ListTopicsResult listTopicsResult = adminClient.listTopics(new ListTopicsOptions().listInternal(true));\n        Set<String> names = listTopicsResult.names().get();\n        names.forEach(name -> {\n            try {\n                Map<String, TopicDescription> map = adminClient.describeTopics(Collections.singleton(name)).all().get(3L, TimeUnit.SECONDS);\n                map.forEach((key, value) -> value.partitions().forEach(info -> extractedOffset(builder, adminClient, name, value, info)));\n            } catch (TimeoutException | InterruptedException | ExecutionException e) {\n                log.warn("Topic {} get offset fail", name);\n            }\n        });\n    }\n\n    private void extractedOffset(CollectRep.MetricsData.Builder builder, AdminClient adminClient, String name, TopicDescription value, TopicPartitionInfo info) {\n        try {\n            TopicPartition topicPartition = new TopicPartition(value.name(), info.partition());\n            long earliestOffset = getEarliestOffset(adminClient, topicPartition);\n            long latestOffset = getLatestOffset(adminClient, topicPartition);\n            CollectRep.ValueRow.Builder valueRowBuilder = CollectRep.ValueRow.newBuilder();\n            valueRowBuilder.addColumns(value.name());\n            valueRowBuilder.addColumns(String.valueOf(info.partition()));\n            valueRowBuilder.addColumns(String.valueOf(earliestOffset));\n            valueRowBuilder.addColumns(String.valueOf(latestOffset));\n            builder.addValues(valueRowBuilder.build());\n        } catch (TimeoutException | InterruptedException | ExecutionException e) {\n            log.warn("Topic {} get offset fail", name);\n        }\n    }\n\n    /**\n     * Get the earliest offset for a given topic partition\n     *\n     * @param adminClient    The AdminClient\n     * @param topicPartition The TopicPartition\n     * @return The earliest offset\n     */\n    private long getEarliestOffset(AdminClient adminClient, TopicPartition topicPartition)\n            throws InterruptedException, ExecutionException, TimeoutException {\n        return adminClient\n                .listOffsets(Collections.singletonMap(topicPartition, OffsetSpec.earliest()))\n                .all()\n                .get(3L, TimeUnit.SECONDS)\n                .get(topicPartition)\n                .offset();\n    }\n\n    /**\n     * Get the latest offset for a given topic partition\n     *\n     * @param adminClient    The AdminClient\n     * @param topicPartition The TopicPartition\n     * @return The latest offset\n     */\n    private long getLatestOffset(AdminClient adminClient, TopicPartition topicPartition)\n            throws InterruptedException, ExecutionException, TimeoutException {\n        return adminClient\n                .listOffsets(Collections.singletonMap(topicPartition, OffsetSpec.latest()))\n                .all()\n                .get(3L, TimeUnit.SECONDS)\n                .get(topicPartition)\n                .offset();\n    }\n\n    /**\n     * Collect the list of topics\n     *\n     * @param builder     The MetricsData builder\n     * @param adminClient The AdminClient\n     */\n    private static void collectTopicList(CollectRep.MetricsData.Builder builder, AdminClient adminClient) throws InterruptedException, ExecutionException {\n        ListTopicsOptions options = new ListTopicsOptions().listInternal(true);\n        Set<String> names = adminClient.listTopics(options).names().get();\n        names.forEach(name -> {\n            CollectRep.ValueRow valueRow = CollectRep.ValueRow.newBuilder().addColumns(name).build();\n            builder.addValues(valueRow);\n        });\n    }\n\n    /**\n     * Collect the description of each topic\n     *\n     * @param builder     The MetricsData builder\n     * @param adminClient The AdminClient\n     */\n    private static void collectTopicDescribe(CollectRep.MetricsData.Builder builder, AdminClient adminClient) throws InterruptedException, ExecutionException {\n        ListTopicsOptions options = new ListTopicsOptions();\n        options.listInternal(true);\n        ListTopicsResult listTopicsResult = adminClient.listTopics(options);\n        Set<String> names = listTopicsResult.names().get();\n        DescribeTopicsResult describeTopicsResult = adminClient.describeTopics(names);\n        Map<String, TopicDescription> map = describeTopicsResult.all().get();\n        map.forEach((key, value) -> {\n            List<TopicPartitionInfo> listp = value.partitions();\n            listp.forEach(info -> {\n                CollectRep.ValueRow.Builder valueRowBuilder = CollectRep.ValueRow.newBuilder();\n                valueRowBuilder.addColumns(value.name());\n                valueRowBuilder.addColumns(String.valueOf(value.partitions().size()));\n                valueRowBuilder.addColumns(String.valueOf(info.partition()));\n                valueRowBuilder.addColumns(info.leader().host());\n                valueRowBuilder.addColumns(String.valueOf(info.leader().port()));\n                valueRowBuilder.addColumns(String.valueOf(info.replicas().size()));\n                valueRowBuilder.addColumns(String.valueOf(info.replicas()));\n                builder.addValues(valueRowBuilder.build());\n            });\n        });\n    }\n\n    @Override\n    public String supportProtocol() {\n        return DispatchConstants.PROTOCOL_KAFKA;\n    }\n}\n')),(0,a.yg)("h3",{id:"7-\u914d\u7f6espi\u670d\u52a1\u6587\u4ef6"},"7. \u914d\u7f6eSPI\u670d\u52a1\u6587\u4ef6"),(0,a.yg)("p",null,"\u5728",(0,a.yg)("inlineCode",{parentName:"p"},"collector/collector/src/main/resources/META-INF/services/org.apache.hertzbeat.collector.collect.AbstractCollect"),"\u6587\u4ef6\u4e2d\uff0c\u6dfb\u52a0",(0,a.yg)("inlineCode",{parentName:"p"},"KafkaCollectImpl"),"\u7c7b\u3002"),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-text"},"...\norg.apache.hertzbeat.collector.collect.kafka.KafkaCollectImpl\n")),(0,a.yg)("h3",{id:"8-\u5728collector\u6a21\u5757\u6dfb\u52a0kafka\u4f9d\u8d56"},"8. \u5728Collector\u6a21\u5757\u6dfb\u52a0Kafka\u4f9d\u8d56"),(0,a.yg)("p",null,"\u6700\u540e\u4e00\u6b65\u662f\u5728",(0,a.yg)("inlineCode",{parentName:"p"},"collector/collector/pom.xml"),"\u4e2d\u6dfb\u52a0",(0,a.yg)("inlineCode",{parentName:"p"},"kafka-collector"),"\u6a21\u5757\u7684\u4f9d\u8d56\uff1a"),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-xml"},"<dependency>\n    <groupId>org.apache.hertzbeat</groupId>\n    <artifactId>hertzbeat-collector-kafka</artifactId>\n    <version>${hertzbeat.version}</version>\n</dependency>\n")),(0,a.yg)("p",null,"\u901a\u8fc7\u4ee5\u4e0a\u6b65\u9aa4\uff0c\u6211\u4eec\u5c31\u5b8c\u6210\u4e86\u4e00\u4e2aKafka Collector\u7684\u5f00\u53d1\uff0c\u4ece\u534f\u8bae\u5b9a\u4e49\u5230\u6700\u7ec8\u7684SPI\u914d\u7f6e\u548c\u4f9d\u8d56\u7ba1\u7406\uff0c\u5b8c\u6574\u7684\u6269\u5c55\u4e86\u4e00\u4e2aKafka\u76d1\u63a7\u6a21\u5757\u3002"),(0,a.yg)("h2",{id:"\u6dfb\u52a0\u914d\u7f6e\u89e3\u6790\u6587\u4ef6"},"\u6dfb\u52a0\u914d\u7f6e\u89e3\u6790\u6587\u4ef6"),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-yaml"},"# Licensed to the Apache Software Foundation (ASF) under one or more\n# contributor license agreements.  See the NOTICE file distributed with\n# this work for additional information regarding copyright ownership.\n# The ASF licenses this file to You under the Apache License, Version 2.0\n# (the \"License\"); you may not use this file except in compliance with\n# the License.  You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# The monitoring type category\uff1aservice-application service monitoring db-database monitoring custom-custom monitoring os-operating system monitoring\ncategory: mid\n# The monitoring type eg: linux windows tomcat mysql aws...\napp: kafka_client\n# The monitoring i18n name\nname:\n  zh-CN: Kafka\u6d88\u606f\u7cfb\u7edf\uff08\u5ba2\u6237\u7aef\uff09\n  en-US: Kafka Message\uff08Client\uff09\n# The description and help of this monitoring type\nhelp:\n  zh-CN: HertzBeat \u4f7f\u7528 <a href=\"https://hertzbeat.apache.org/docs/advanced/extend-jmx\">Kafka Admin Client</a> \u5bf9 Kafka \u7684\u901a\u7528\u6307\u6807\u8fdb\u884c\u91c7\u96c6\u76d1\u63a7\u3002</span>\n  en-US: HertzBeat uses <a href='https://hertzbeat.apache.org/docs/advanced/extend-jmx'>Kafka Admin Client</a> to monitoring kafka general metrics. </span>\n  zh-TW: HertzBeat \u4f7f\u7528 <a href=\"https://hertzbeat.apache.org/docs/advanced/extend-jmx\">Kafka Admin Client</a> \u5c0d Kafka \u7684\u901a\u7528\u6307\u6a19\u9032\u884c\u91c7\u96c6\u76e3\u63a7\u3002</span>\nhelpLink:\n  zh-CN: https://hertzbeat.apache.org/zh-cn/docs/help/kafka_client\n  en-US: https://hertzbeat.apache.org/docs/help/kafka_client\n# Input params define for monitoring(render web ui by the definition)\nparams:\n  # field-param field key\n  - field: host\n    # name-param field display i18n name\n    name:\n      zh-CN: \u76ee\u6807Host\n      en-US: Target Host\n    # type-param field type(most mapping the html input type)\n    type: host\n    # required-true or false\n    required: true\n  - field: port\n    name:\n      zh-CN: \u7aef\u53e3\n      en-US: Port\n    type: number\n    # when type is number, range is required\n    range: '[0,65535]'\n    required: true\n    defaultValue: 9092\n\n# collect metrics config list\nmetrics:\n  # metrics - server_info\n  - name: topic_list\n    i18n:\n      zh-CN: \u4e3b\u9898\u5217\u8868\n      en-US: Topic List\n    # metrics scheduling priority(0->127)->(high->low), metrics with the same priority will be scheduled in parallel\n    # priority 0's metrics is availability metrics, it will be scheduled first, only availability metrics collect success will the scheduling continue\n    priority: 0\n    # collect metrics content\n    fields:\n      # field-metric name, type-metric type(0-number,1-string), unit-metric unit('%','ms','MB'), label-whether it is a metrics label field\n      - field: TopicName\n        type: 1\n        i18n:\n          zh-CN: \u4e3b\u9898\u540d\u79f0\n          en-US: Topic Name\n    # the protocol used for monitoring, eg: sql, ssh, http, telnet, wmi, snmp, sdk\n    protocol: kclient\n    # the config content when protocol is jmx\n    kclient:\n      host: ^_^host^_^\n      port: ^_^port^_^\n      command: topic-list\n  - name: topic_detail\n    i18n:\n      zh-CN: \u4e3b\u9898\u8be6\u7ec6\u4fe1\u606f\n      en-US: Topic Detail Info\n    # metrics scheduling priority(0->127)->(high->low), metrics with the same priority will be scheduled in parallel\n    # priority 0's metrics is availability metrics, it will be scheduled first, only availability metrics collect success will the scheduling continue\n    priority: 0\n    # collect metrics content\n    fields:\n      # field-metric name, type-metric type(0-number,1-string), unit-metric unit('%','ms','MB'), label-whether it is a metrics label field\n      - field: TopicName\n        type: 1\n        i18n:\n          zh-CN: \u4e3b\u9898\u540d\u79f0\n          en-US: Topic Name\n      - field: PartitionNum\n        type: 1\n        i18n:\n          zh-CN: \u5206\u533a\u6570\u91cf\n          en-US: Partition Num\n      - field: PartitionLeader\n        type: 1\n        i18n:\n          zh-CN: \u5206\u533a\u9886\u5bfc\u8005\n          en-US: Partition Leader\n      - field: BrokerHost\n        type: 1\n        i18n:\n          zh-CN: Broker\u4e3b\u673a\n          en-US: Broker Host\n      - field: BrokerPort\n        type: 1\n        i18n:\n          zh-CN: Broker\u7aef\u53e3\n          en-US: Broker Port\n      - field: ReplicationFactorSize\n        type: 1\n        i18n:\n          zh-CN: \u590d\u5236\u56e0\u5b50\u5927\u5c0f\n          en-US: Replication Factor Size\n      - field: ReplicationFactor\n        type: 1\n        i18n:\n          zh-CN: \u590d\u5236\u56e0\u5b50\n          en-US: Replication Factor\n    # the protocol used for monitoring, eg: sql, ssh, http, telnet, wmi, snmp, sdk\n    protocol: kclient\n    # the config content when protocol is jmx\n    kclient:\n      host: ^_^host^_^\n      port: ^_^port^_^\n      command: topic-describe\n  - name: topic_offset\n    i18n:\n      zh-CN: \u4e3b\u9898\u504f\u79fb\u91cf\n      en-US: Topic Offset\n    # metrics scheduling priority(0->127)->(high->low), metrics with the same priority will be scheduled in parallel\n    # priority 0's metrics is availability metrics, it will be scheduled first, only availability metrics collect success will the scheduling continue\n    priority: 0\n    # collect metrics content\n    fields:\n      # field-metric name, type-metric type(0-number,1-string), unit-metric unit('%','ms','MB'), label-whether it is a metrics label field\n      - field: TopicName\n        type: 1\n        i18n:\n          zh-CN: \u4e3b\u9898\u540d\u79f0\n          en-US: Topic Name\n      - field: PartitionNum\n        type: 1\n        i18n:\n          zh-CN: \u5206\u533a\u6570\u91cf\n          en-US: Partition Num\n      - field: earliest\n        type: 0\n        i18n:\n          zh-CN: \u6700\u65e9\u504f\u79fb\u91cf\n          en-US: Earliest Offset\n      - field: latest\n        type: 0\n        i18n:\n          zh-CN: \u6700\u65b0\u504f\u79fb\u91cf\n          en-US: Latest Offset\n    # the protocol used for monitoring, eg: sql, ssh, http, telnet, wmi, snmp, sdk\n    protocol: kclient\n    # the config content when protocol is jmx\n    kclient:\n      host: ^_^host^_^\n      port: ^_^port^_^\n      command: topic-offset\n\n")),(0,a.yg)("p",null,"\u5230\u8fd9\u91cc\u81ea\u5b9a\u4e49\u5f00\u53d1",(0,a.yg)("inlineCode",{parentName:"p"},"collector"),"\u5c31\u5b8c\u6210\u4e86\uff0c\u542f\u52a8\u670d\u52a1\u5c31\u53ef\u4ee5\u6309\u7167\u6b63\u5e38\u903b\u8f91\u5f00\u59cb\u76d1\u63a7\u6307\u6807\u3002"),(0,a.yg)("h2",{id:"\u5f00\u53d1\u8c03\u8bd5"},"\u5f00\u53d1\u8c03\u8bd5"),(0,a.yg)("p",null,"\u672c\u5730\u542f\u52a8",(0,a.yg)("inlineCode",{parentName:"p"},"manager"),"\u6a21\u5757\u65f6\uff0c\u5982\u679c\u63d0\u793a\u6211\u4eec\u6dfb\u52a0\u7684\u76d1\u63a7\u627e\u4e0d\u5230\u7c7b\uff0c\u5c06\u4f9d\u8d56\u518d\u6dfb\u52a0\u5230",(0,a.yg)("inlineCode",{parentName:"p"},"manager"),"\u6a21\u5757\u4e0b\u3002"),(0,a.yg)("p",null,(0,a.yg)("strong",{parentName:"p"},"\u6ce8\u610f\uff1a\u6253\u5305\u63d0\u4ea4\u4ee3\u7801\u65f6\uff0c\u4e0d\u9700\u8981\u5c06",(0,a.yg)("inlineCode",{parentName:"strong"},"manager"),"\u6a21\u5757\u4e0b\u7684\u4f9d\u8d56\u63d0\u4ea4\u3002")),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-xml"},"    \x3c!-- collector-kafka --\x3e\n        <dependency>\n            <groupId>org.apache.hertzbeat</groupId>\n            <artifactId>hertzbeat-collector-kafka</artifactId>\n            <version>${hertzbeat.version}</version>\n        </dependency>\n")))}m.isMDXComponent=!0},53384(e,n,t){t.d(n,{A:()=>i});const i=t.p+"assets/images/model-desc-d1a4d60dbef4934877da653ae2a1eb75.png"},58860(e,n,t){t.d(n,{xA:()=>s,yg:()=>u});var i=t(37953);function a(e,n,t){return n in e?Object.defineProperty(e,n,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[n]=t,e}function o(e,n){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);n&&(i=i.filter(function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable})),t.push.apply(t,i)}return t}function r(e){for(var n=1;n<arguments.length;n++){var t=null!=arguments[n]?arguments[n]:{};n%2?o(Object(t),!0).forEach(function(n){a(e,n,t[n])}):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):o(Object(t)).forEach(function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(t,n))})}return e}function l(e,n){if(null==e)return{};var t,i,a=function(e,n){if(null==e)return{};var t,i,a={},o=Object.keys(e);for(i=0;i<o.length;i++)t=o[i],n.indexOf(t)>=0||(a[t]=e[t]);return a}(e,n);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(i=0;i<o.length;i++)t=o[i],n.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(a[t]=e[t])}return a}var c=i.createContext({}),p=function(e){var n=i.useContext(c),t=n;return e&&(t="function"==typeof e?e(n):r(r({},n),e)),t},s=function(e){var n=p(e.components);return i.createElement(c.Provider,{value:n},e.children)},m={inlineCode:"code",wrapper:function(e){var n=e.children;return i.createElement(i.Fragment,{},n)}},d=i.forwardRef(function(e,n){var t=e.components,a=e.mdxType,o=e.originalType,c=e.parentName,s=l(e,["components","mdxType","originalType","parentName"]),d=p(t),u=a,g=d["".concat(c,".").concat(u)]||d[u]||m[u]||o;return t?i.createElement(g,r(r({ref:n},s),{},{components:t})):i.createElement(g,r({ref:n},s))});function u(e,n){var t=arguments,a=n&&n.mdxType;if("string"==typeof e||a){var o=t.length,r=new Array(o);r[0]=d;var l={};for(var c in n)hasOwnProperty.call(n,c)&&(l[c]=n[c]);l.originalType=e,l.mdxType="string"==typeof e?e:a,r[1]=l;for(var p=2;p<o;p++)r[p]=t[p];return i.createElement.apply(null,r)}return i.createElement.apply(null,t)}d.displayName="MDXCreateElement"},98039(e,n,t){t.d(n,{A:()=>i});const i=t.p+"assets/images/model-create-26dd8d16e6bfc29a7cb414169a832feb.png"}}]);